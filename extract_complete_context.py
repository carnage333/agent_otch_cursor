import docx
import re
from typing import List, Dict, Any

def extract_complete_data_from_docx(file_path: str) -> Dict[str, Any]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –í–°–ï –¥–∞–Ω–Ω—ã–µ –∏–∑ Word –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    try:
        doc = docx.Document(file_path)
        full_text = ""
        
        print("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ñ–∞–π–ª–∞...")
        
        for paragraph in doc.paragraphs:
            text = paragraph.text.strip()
            if text:
                full_text += text + "\n"
        
        print(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(full_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ –¥–∞–Ω–Ω—ã–µ
        data = {
            'full_text': full_text,
            'metrics': extract_metrics(full_text),
            'formulas': extract_formulas(full_text),
            'terms': extract_terms(full_text),
            'report_structures': extract_report_structures(full_text),
            'campaigns': extract_campaigns(full_text),
            'platforms': extract_platforms(full_text),
            'business_units': extract_business_units(full_text)
        }
        
        return data
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        return {}

def extract_metrics(text: str) -> List[Dict]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∏ –∏—Ö –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è"""
    metrics = []
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –º–µ—Ç—Ä–∏–∫
    patterns = [
        r'([A-Z]{2,4})\s*\(([^)]+)\):\s*(.+?)(?:\.|$)',  # AOV (Average Order Value): –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        r'([A-Z]{2,4}):\s*(.+?)(?:\.|$)',  # AOV: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
    ]
    
    for pattern in patterns:
        try:
            matches = re.finditer(pattern, text, re.MULTILINE | re.DOTALL)
            for match in matches:
                try:
                    metric_code = match.group(1)
                    if len(match.groups()) > 1:
                        metric_name = match.group(2)
                        definition = match.group(3)
                    else:
                        metric_name = ""
                        definition = match.group(2)
                    
                    if len(metric_code) >= 2 and len(definition) > 10:
                        metrics.append({
                            'code': metric_code,
                            'name': metric_name,
                            'definition': definition.strip(),
                            'full_match': match.group(0)
                        })
                except IndexError:
                    continue
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≤ –ø–∞—Ç—Ç–µ—Ä–Ω–µ {pattern}: {e}")
            continue
    
    return metrics

def extract_formulas(text: str) -> List[Dict]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–æ—Ä–º—É–ª—ã —Ä–∞—Å—á–µ—Ç–∞"""
    formulas = []
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ñ–æ—Ä–º—É–ª
    patterns = [
        r'–§–æ—Ä–º—É–ª–∞ —Ä–∞—Å—á–µ—Ç–∞:\s*(.+?)(?:\.|$)',  # –§–æ—Ä–º—É–ª–∞ —Ä–∞—Å—á–µ—Ç–∞: —Ñ–æ—Ä–º—É–ª–∞
        r'–†–∞—Å—á–µ—Ç:\s*(.+?)(?:\.|$)',  # –†–∞—Å—á–µ—Ç: —Ñ–æ—Ä–º—É–ª–∞
        r'–§–æ—Ä–º—É–ª–∞:\s*(.+?)(?:\.|$)',  # –§–æ—Ä–º—É–ª–∞: —Ñ–æ—Ä–º—É–ª–∞
    ]
    
    for pattern in patterns:
        try:
            matches = re.finditer(pattern, text, re.MULTILINE | re.DOTALL)
            for match in matches:
                formula = match.group(1).strip()
                if len(formula) > 5:
                    formulas.append({
                        'formula': formula,
                        'context': match.group(0)
                    })
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≤ –ø–∞—Ç—Ç–µ—Ä–Ω–µ —Ñ–æ—Ä–º—É–ª {pattern}: {e}")
            continue
    
    return formulas

def extract_terms(text: str) -> List[Dict]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ—Ä–º–∏–Ω—ã –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è"""
    terms = []
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —Å—Ç—Ä–æ–∫–∏
    lines = text.split('\n')
    
    for line in lines:
        line = line.strip()
        if not line or len(line) < 5:
            continue
        
        # –ò—â–µ–º —Ä–∞–∑–ª–∏—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        patterns = [
            r'^([–ê-–Ø][–ê-–Ø\s\d]+):\s*(.+)',  # –¢–ï–†–ú–ò–ù: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
            r'^([–ê-–Ø][–ê-–Ø\s\d]+)\s*-\s*(.+)',  # –¢–ï–†–ú–ò–ù - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ  
            r'^([–ê-–Ø][–ê-–Ø\s\d]+)\s*=\s*(.+)',  # –¢–ï–†–ú–ò–ù = –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
            r'^([–ê-–Ø][–ê-–Ø\s\d]+)\s*\((.+)\)',  # –¢–ï–†–ú–ò–ù (–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ)
            r'^([–ê-–Ø][–ê-–Ø\s\d]+)\.\s*(.+)',  # –¢–ï–†–ú–ò–ù. –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ
        ]
        
        for pattern in patterns:
            try:
                match = re.search(pattern, line)
                if match:
                    term = match.group(1).strip()
                    definition = match.group(2).strip()
                    
                    # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏–ª–∏ –Ω–µ—Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ
                    if (len(term) > 2 and len(definition) > 10 and 
                        not term.isdigit() and not definition.isdigit()):
                        
                        terms.append({
                            'term': term,
                            'definition': definition,
                            'line': line
                        })
                        break
            except Exception as e:
                continue
    
    return terms

def extract_report_structures(text: str) -> List[Dict]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –æ—Ç—á–µ—Ç–æ–≤"""
    structures = []
    
    # –ò—â–µ–º —Ä–∞–∑–¥–µ–ª—ã —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º –æ—Ç—á–µ—Ç–æ–≤
    sections = re.split(r'\n\d+\.\s*', text)
    
    for section in sections:
        if any(keyword in section.lower() for keyword in ['–æ—Ç—á–µ—Ç', '—Å—Ç—Ä—É–∫—Ç—É—Ä–∞', '—Ä–∞–∑–¥–µ–ª', '–∞–Ω–∞–ª–∏–∑']):
            lines = section.split('\n')
            title = lines[0].strip() if lines else ""
            content = '\n'.join(lines[1:]).strip()
            
            if len(content) > 20:
                structures.append({
                    'title': title,
                    'content': content
                })
    
    return structures

def extract_campaigns(text: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏—è –∫–∞–º–ø–∞–Ω–∏–π"""
    campaigns = []
    
    # –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫–∞–º–ø–∞–Ω–∏–π
    patterns = [
        r'–∫–∞–º–ø–∞–Ω–∏—è[:\s]+([–ê-–Ø][–ê-–Ø\s\d]+)',
        r'–§–†–ö\d+',
        r'–∫–∞–º–ø–∞–Ω–∏—è\s+([–ê-–Ø][–ê-–Ø\s\d]+)',
    ]
    
    for pattern in patterns:
        try:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                try:
                    campaign = match.group(1) if len(match.groups()) > 0 else match.group(0)
                    if campaign not in campaigns:
                        campaigns.append(campaign)
                except IndexError:
                    continue
        except Exception as e:
            continue
    
    return campaigns

def extract_platforms(text: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã"""
    platforms = []
    
    # –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –ø–ª–∞—Ç—Ñ–æ—Ä–º
    platform_keywords = ['–ø–ª–∞—Ç—Ñ–æ—Ä–º–∞', '—Å–∏—Å—Ç–µ–º–∞', '—Å–µ—Ä–≤–∏—Å', '–∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç']
    
    lines = text.split('\n')
    for line in lines:
        for keyword in platform_keywords:
            if keyword in line.lower():
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã
                try:
                    match = re.search(r'([–ê-–Ø][–ê-–Ø\s\d]+)', line)
                    if match:
                        platform = match.group(1)
                        if platform not in platforms:
                            platforms.append(platform)
                except Exception:
                    continue
    
    return platforms

def extract_business_units(text: str) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –±–∏–∑–Ω–µ—Å-–µ–¥–∏–Ω–∏—Ü—ã"""
    units = []
    
    # –ò—â–µ–º —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –±–∏–∑–Ω–µ—Å-–µ–¥–∏–Ω–∏—Ü
    patterns = [
        r'—Ç—Ä–∞–π–±[:\s]+([–ê-–Ø][–ê-–Ø\s\d]+)',
        r'–ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ[:\s]+([–ê-–Ø][–ê-–Ø\s\d]+)',
        r'–¥–µ–ø–∞—Ä—Ç–∞–º–µ–Ω—Ç[:\s]+([–ê-–Ø][–ê-–Ø\s\d]+)',
    ]
    
    for pattern in patterns:
        try:
            matches = re.finditer(pattern, text, re.IGNORECASE)
            for match in matches:
                try:
                    unit = match.group(1)
                    if unit not in units:
                        units.append(unit)
                except IndexError:
                    continue
        except Exception as e:
            continue
    
    return units

def show_complete_extracted_data():
    """–ü–æ–∫–∞–∑—ã–≤–∞–µ—Ç –≤—Å–µ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ"""
    data = extract_complete_data_from_docx("–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.docx")
    
    if not data:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª")
        return
    
    print("\n" + "=" * 80)
    print("üìä –ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó –î–ê–ù–ù–´–•:")
    print("=" * 80)
    
    print(f"\nüìà –ú–ï–¢–†–ò–ö–ò ({len(data['metrics'])}):")
    for i, metric in enumerate(data['metrics'], 1):
        print(f"{i:2d}. {metric['code']} - {metric['definition'][:100]}...")
    
    print(f"\nüßÆ –§–û–†–ú–£–õ–´ ({len(data['formulas'])}):")
    for i, formula in enumerate(data['formulas'], 1):
        print(f"{i:2d}. {formula['formula']}")
    
    print(f"\nüìù –¢–ï–†–ú–ò–ù–´ ({len(data['terms'])}):")
    for i, term in enumerate(data['terms'], 1):
        print(f"{i:2d}. {term['term']} - {term['definition'][:80]}...")
    
    print(f"\nüìã –°–¢–†–£–ö–¢–£–†–´ –û–¢–ß–ï–¢–û–í ({len(data['report_structures'])}):")
    for i, structure in enumerate(data['report_structures'], 1):
        print(f"{i:2d}. {structure['title']}")
        print(f"    {structure['content'][:100]}...")
    
    print(f"\nüéØ –ö–ê–ú–ü–ê–ù–ò–ò ({len(data['campaigns'])}):")
    for i, campaign in enumerate(data['campaigns'], 1):
        print(f"{i:2d}. {campaign}")
    
    print(f"\nüñ•Ô∏è –ü–õ–ê–¢–§–û–†–ú–´ ({len(data['platforms'])}):")
    for i, platform in enumerate(data['platforms'], 1):
        print(f"{i:2d}. {platform}")
    
    print(f"\nüè¢ –ë–ò–ó–ù–ï–°-–ï–î–ò–ù–ò–¶–´ ({len(data['business_units'])}):")
    for i, unit in enumerate(data['business_units'], 1):
        print(f"{i:2d}. {unit}")
    
    return data

if __name__ == "__main__":
    show_complete_extracted_data() 