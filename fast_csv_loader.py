import pandas as pd
import sqlite3
import time
import csv
import re
import os

def parse_csv_line(line):
    """–ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫—É CSV —Å –≤–ª–æ–∂–µ–Ω–Ω—ã–º–∏ –∫–∞–≤—ã—á–∫–∞–º–∏"""
    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –∫–∞–≤—ã—á–∫–∏ –ø–æ –∫—Ä–∞—è–º
    line = line.strip()
    if line.startswith('"') and line.endswith('"'):
        line = line[1:-1]
    
    # –†–∞–∑–±–∏–≤–∞–µ–º –ø–æ –∑–∞–ø—è—Ç–æ–π, –Ω–æ —É—á–∏—Ç—ã–≤–∞–µ–º –∫–∞–≤—ã—á–∫–∏
    result = []
    current = ""
    in_quotes = False
    i = 0
    
    while i < len(line):
        char = line[i]
        
        if char == '"':
            if in_quotes and i + 1 < len(line) and line[i + 1] == '"':
                # –î–≤–æ–π–Ω–∞—è –∫–∞–≤—ã—á–∫–∞ –≤–Ω—É—Ç—Ä–∏ –∫–∞–≤—ã—á–µ–∫
                current += '"'
                i += 2
            else:
                # –û–¥–∏–Ω–æ—á–Ω–∞—è –∫–∞–≤—ã—á–∫–∞
                in_quotes = not in_quotes
                i += 1
        elif char == ',' and not in_quotes:
            # –ó–∞–ø—è—Ç–∞—è –≤–Ω–µ –∫–∞–≤—ã—á–µ–∫ - —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
            result.append(current.strip())
            current = ""
            i += 1
        else:
            current += char
            i += 1
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
    result.append(current.strip())
    return result

def preprocess_csv_manual(input_path, output_path):
    """–°–æ–∑–¥–∞—ë—Ç –æ—á–∏—â–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é CSV —Å —Ä—É—á–Ω—ã–º –ø–∞—Ä—Å–∏–Ω–≥–æ–º"""
    with open(input_path, 'r', encoding='utf-8') as fin, open(output_path, 'w', encoding='utf-8', newline='') as fout:
        for line_num, line in enumerate(fin, 1):
            if line_num == 1:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫
                parsed = parse_csv_line(line)
                # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 15 —Å—Ç–æ–ª–±—Ü–æ–≤ (–æ—Å–Ω–æ–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
                header = parsed[:15]
                # –û—á–∏—â–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –æ—Ç –ª–∏—à–Ω–∏—Ö –∫–∞–≤—ã—á–µ–∫
                clean_header = []
                for col in header:
                    col = col.replace('""', '"')
                    col = re.sub(r'^"|"$', '', col)
                    clean_header.append(col)
                fout.write(','.join(clean_header) + '\n')
            else:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ
                parsed = parse_csv_line(line)
                # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 15 —Å—Ç–æ–ª–±—Ü–æ–≤
                data = parsed[:15]
                # –û—á–∏—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ç –ª–∏—à–Ω–∏—Ö –∫–∞–≤—ã—á–µ–∫
                clean_data = []
                for val in data:
                    val = val.replace('""', '"')
                    val = re.sub(r'^"|"$', '', val)
                    clean_data.append(val)
                fout.write(','.join(clean_data) + '\n')

def get_column_mapping(columns):
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞–ø–ø–∏–Ω–≥ –∫–æ–ª–æ–Ω–æ–∫ CSV -> funnel_data"""
    mapping = {
        'date': 'date',
        'lastTrafficSource': 'traffic_source',
        'traffic_source': 'traffic_source',
        'UTMCampaign_clear': 'utm_campaign',
        'utm_campaign': 'utm_campaign',
        'UTMSource': 'utm_source',
        'utm_source': 'utm_source',
        'UTMMedium': 'utm_medium',
        'utm_medium': 'utm_medium',
        'UTMContent': 'utm_content',
        'utm_content': 'utm_content',
        'UTMTerm': 'utm_term',
        'utm_term': 'utm_term',
        'visitID': 'visit_id',
        'visit_id': 'visit_id',
        'submits': 'submits',
        'res': 'res',
        'subs_all': 'subs_all',
        'account_num': 'account_num',
        'created_flag': 'created_flag',
        'call_answered_flag': 'call_answered_flag',
        'quality_flag': 'quality_flag',
        'quality': 'quality',
    }
    return {col: mapping[col] for col in columns if col in mapping}

def create_funnel_table(conn):
    conn.execute('''
        CREATE TABLE IF NOT EXISTS funnel_data (
            date TEXT,
            traffic_source TEXT,
            utm_campaign TEXT,
            utm_source TEXT,
            utm_medium TEXT,
            utm_content TEXT,
            utm_term TEXT,
            visit_id TEXT,
            submits REAL,
            res REAL,
            subs_all REAL,
            account_num INTEGER,
            created_flag INTEGER,
            call_answered_flag INTEGER,
            quality_flag INTEGER,
            quality INTEGER
        )
    ''')
    conn.commit()

def fast_load_csv_to_db(csv_file, db_path='marketing_analytics.db', chunk_size=10000):
    print(f"\nüöÄ –ë—ã—Å—Ç—Ä–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ {csv_file} –≤ funnel_data...")
    start = time.time()
    
    # –°–æ–∑–¥–∞–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    temp_file = 'cleaned_funnel_sample.csv'
    preprocess_csv_manual(csv_file, temp_file)
    print(f"‚úÖ –°–æ–∑–¥–∞–Ω –æ—á–∏—â–µ–Ω–Ω—ã–π —Ñ–∞–π–ª: {temp_file}")
    
    conn = sqlite3.connect(db_path)
    create_funnel_table(conn)
    conn.execute('DELETE FROM funnel_data')
    print("üóëÔ∏è –û—á–∏—â–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ funnel_data")
    
    total = 0
    chunk_num = 0
    
    # –ß–∏—Ç–∞–µ–º –æ—á–∏—â–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    reader = pd.read_csv(
        temp_file,
        sep=',',
        dtype=str,
        on_bad_lines='skip',
        header=0
    )
    
    print(f"üìä –ó–∞–≥–æ–ª–æ–≤–∫–∏: {list(reader.columns)}")
    print(f"üìä –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: {len(reader)} —Å—Ç—Ä–æ–∫")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ —á–∞–Ω–∫–∞–º–∏
    for chunk_start in range(0, len(reader), chunk_size):
        chunk_num += 1
        chunk_end = min(chunk_start + chunk_size, len(reader))
        chunk = reader.iloc[chunk_start:chunk_end].copy()
        
        # –ú–∞–ø–ø–∏–Ω–≥ –∫–æ–ª–æ–Ω–æ–∫
        mapping = get_column_mapping(chunk.columns)
        chunk = chunk.rename(columns=mapping)
        
        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
        expected = [
            'date', 'traffic_source', 'utm_campaign', 'utm_source', 'utm_medium',
            'utm_content', 'utm_term', 'visit_id', 'submits', 'res', 'subs_all',
            'account_num', 'created_flag', 'call_answered_flag', 'quality_flag', 'quality'
        ]
        
        for col in expected:
            if col not in chunk.columns:
                chunk[col] = None
        
        chunk = chunk[expected]
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ –ë–î
        chunk.to_sql('funnel_data', conn, if_exists='append', index=False, method=None)
        total += len(chunk)
        print(f"üì¶ –ß–∞–Ω–∫ {chunk_num}: {len(chunk)} —Å—Ç—Ä–æ–∫ (–≤—Å–µ–≥–æ: {total})")
    
    conn.commit()
    print(f"‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {total}. –í—Ä–µ–º—è: {time.time()-start:.1f} —Å–µ–∫.")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã
    sample = conn.execute('SELECT * FROM funnel_data LIMIT 3').fetchall()
    print("\nüìã –ü—Ä–∏–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö:")
    for row in sample:
        print(row)
    
    campaigns = conn.execute('SELECT DISTINCT utm_campaign FROM funnel_data WHERE utm_campaign IS NOT NULL LIMIT 10').fetchall()
    print(f"üéØ –ü—Ä–∏–º–µ—Ä—ã utm_campaign: {[c[0] for c in campaigns]}")
    
    sources = conn.execute('SELECT DISTINCT utm_source FROM funnel_data WHERE utm_source IS NOT NULL LIMIT 5').fetchall()
    print(f"üåê –ü—Ä–∏–º–µ—Ä—ã utm_source: {[s[0] for s in sources]}")
    
    conn.close()
    
    # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
    if os.path.exists(temp_file):
        os.remove(temp_file)

if __name__ == "__main__":
    fast_load_csv_to_db('rko_funnel_sample-1750856109631.csv') 