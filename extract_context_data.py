import docx
import re
from typing import List, Dict

def extract_from_docx(file_path: str) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç –∏–∑ Word –¥–æ–∫—É–º–µ–Ω—Ç–∞"""
    try:
        doc = docx.Document(file_path)
        text = ""
        for paragraph in doc.paragraphs:
            text += paragraph.text + "\n"
        return text
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {e}")
        return ""

def extract_terms_from_text(text: str) -> List[Dict]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ—Ä–º–∏–Ω—ã –∏ –∏—Ö –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
    terms = []
    
    # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ç–∏–ø–∞ "–¢–ï–†–ú–ò–ù: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ" –∏–ª–∏ "–¢–ï–†–ú–ò–ù - –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ"
    patterns = [
        r'([–ê-–Ø][–ê-–Ø\s]+):\s*(.+)',
        r'([–ê-–Ø][–ê-–Ø\s]+)\s*-\s*(.+)',
        r'([–ê-–Ø][–ê-–Ø\s]+)\s*=\s*(.+)',
    ]
    
    lines = text.split('\n')
    for line in lines:
        line = line.strip()
        if not line:
            continue
            
        for pattern in patterns:
            match = re.search(pattern, line)
            if match:
                term = match.group(1).strip()
                definition = match.group(2).strip()
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
                if len(term) > 2 and len(definition) > 10:
                    terms.append({
                        'term': term,
                        'definition': definition,
                        'line': line
                    })
                break
    
    return terms

def compare_with_rag():
    """–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã —Å RAG —Å–∏—Å—Ç–µ–º–æ–π"""
    from rag_system import RAGSystem
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ Word —Ñ–∞–π–ª–∞
    text = extract_from_docx("–∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.docx")
    if not text:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.docx")
        return
    
    print("üìÑ –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ —Ñ–∞–π–ª–∞:")
    print("=" * 60)
    print(text[:1000] + "..." if len(text) > 1000 else text)
    print("\n" + "=" * 60)
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ—Ä–º–∏–Ω—ã
    extracted_terms = extract_terms_from_text(text)
    
    print(f"\nüîç –ù–∞–π–¥–µ–Ω–æ {len(extracted_terms)} —Ç–µ—Ä–º–∏–Ω–æ–≤ –≤ —Ñ–∞–π–ª–µ:")
    for i, term in enumerate(extracted_terms, 1):
        print(f"{i}. {term['term']}: {term['definition'][:100]}...")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å –≤ RAG —Å–∏—Å—Ç–µ–º–µ
    rag = RAGSystem()
    rag_terms = []
    
    for category, items in rag.knowledge_base.items():
        for item in items:
            rag_terms.append(item.term)
    
    print(f"\nüìö –í RAG —Å–∏—Å—Ç–µ–º–µ –µ—Å—Ç—å {len(rag_terms)} —Ç–µ—Ä–º–∏–Ω–æ–≤:")
    for i, term in enumerate(rag_terms, 1):
        print(f"{i}. {term}")
    
    # –ù–∞—Ö–æ–¥–∏–º —Ç–µ—Ä–º–∏–Ω—ã, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ RAG
    extracted_term_names = [term['term'] for term in extracted_terms]
    missing_terms = []
    
    for term in extracted_terms:
        term_name = term['term']
        found_in_rag = False
        
        for rag_term in rag_terms:
            if term_name.lower() in rag_term.lower() or rag_term.lower() in term_name.lower():
                found_in_rag = True
                break
        
        if not found_in_rag:
            missing_terms.append(term)
    
    print(f"\n‚ùå –¢–µ—Ä–º–∏–Ω—ã, –∫–æ—Ç–æ—Ä—ã—Ö –ù–ï–¢ –≤ RAG —Å–∏—Å—Ç–µ–º–µ ({len(missing_terms)}):")
    for term in missing_terms:
        print(f"- {term['term']}: {term['definition'][:80]}...")
    
    if missing_terms:
        print(f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: –î–æ–±–∞–≤–∏—Ç—å {len(missing_terms)} —Ç–µ—Ä–º–∏–Ω–æ–≤ –≤ RAG —Å–∏—Å—Ç–µ–º—É")
    else:
        print("\n‚úÖ –í—Å–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞ —É–∂–µ –µ—Å—Ç—å –≤ RAG —Å–∏—Å—Ç–µ–º–µ!")

if __name__ == "__main__":
    compare_with_rag() 